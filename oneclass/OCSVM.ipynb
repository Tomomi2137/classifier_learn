{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Class Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "公式ドキュメント：https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html<br>\n",
    "\n",
    "まず，OneClassSupportVectorMachineは異常検知の手法のうち教師データなしのものである．<br>\n",
    "教師なし学習とは,データそのものが持つ構造を浮かび上がらせることで,似たデータ同士にグループ化して分類する手法である．<br>\n",
    "\n",
    "詳細については以下のリンクをみてみるといいかもしれない<br>\n",
    "[異常検知のための One Class SVM](https://qiita.com/kznx/items/434d98bf1a0e39327542)<br>\n",
    "[One Class SVMを用いた異常検知](https://www.slideshare.net/YutoMori2/one-class-svm)<br>\n",
    "[One Class Support Vector Machine(One Class SVM入門)](https://recruit.cct-inc.co.jp/tecblog/machine-learning/one-class-svm/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### はじめに"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wineデータセットに対してOneClassSupportVectorMachineを使用する<br>\n",
    "スケーリング:標準化(平均0, 分散１)<br>\n",
    "今回は学習用データとテスト用データは以下の通りにする<br>\n",
    "学習用：正常データ38個<br>\n",
    "テスト用：正常データ10個, 異常データ10個<br>\n",
    "\n",
    "目的<br>\n",
    "正常データをclass_0としてOCSVMで学習し, FARとFRRで評価を行う．<br>\n",
    "\n",
    "version.など<br>\n",
    "python 3.7.7<br>\n",
    "scikit-learn==0.23.2<br>\n",
    "pandas==1.1.5<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なパッケージを用意\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# スケーリング\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# モデル\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "# warning ignore code\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 表示範囲設定\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの用意: 詳細についてはdataset.ipynbを参照\n",
    "from sklearn.datasets import load_wine\n",
    "data_wine = load_wine()\n",
    "\n",
    "df = pd.DataFrame(data_wine[\"data\"],columns=data_wine[\"feature_names\"])\n",
    "df['target'] = data_wine['target']\n",
    "df['target'] = df['target'].replace({0:'class_0', 1:'class_1', 2:'class_2'})\n",
    "\n",
    "df_all = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_nameに指定したラベルを正常データ\n",
    "# それ以外を異常データとして分ける\n",
    "# 今回はclass_2にあわせて, 学習用に正常データ38個, テスト用に正常データ10個と異常データ10個を使用する\n",
    "\n",
    "def select_data(df_target, target_name):\n",
    "    # target_nameで指定したものをdf1\n",
    "    df1 = df_target[df_target['target'] == target_name]\n",
    "    # target_nameで指定したもの以外をdf2\n",
    "    df2 = df_target[df_target['target'] != target_name]\n",
    "    \n",
    "    # 正常データ(本人)\n",
    "    x_normal = df1.drop('target', axis=1)\n",
    "    y_normal = df1['target']\n",
    "    \n",
    "    # 異常データ(他人)\n",
    "    x_anomaly = df2.drop('target', axis=1)\n",
    "    y_anomaly = df2['target']\n",
    "    \n",
    "    # \n",
    "    # 今回は学習用データの数をそろえる為, train_seizeはclass_2の数からテスト用のデータ数１０個を引いたもの\n",
    "    # train_size, test_seize:0.0~1.0の間で割合 or 個数\n",
    "    x_train_no, x_test_no, y_train_no, y_test_no = train_test_split(x_normal, y_normal, train_size=38, test_size=10, random_state=0, shuffle=True)\n",
    "    _x_train_ano, x_test_ano, _y_train_ano, y_test_ano = train_test_split(x_anomaly, y_anomaly, test_size=10, random_state=0, shuffle=True)\n",
    "    \n",
    "    return x_train_no, x_test_no, y_train_no, y_test_no, x_test_ano, y_test_ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_0の部分はclass_1やclass_2でもOK\n",
    "X_train_no, X_test_no, Y_train_no, Y_test_no, X_test_ano, Y_test_ano = select_data(df_all, 'class_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各データの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_no.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 前処理：標準化（平均０, 分散１）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = preprocessing.StandardScaler()\n",
    "ss.fit(X_train_no)\n",
    "x_train_ss = ss.transform(X_train_no)\n",
    "x_test_no_ss = ss.transform(X_test_no)\n",
    "x_test_ano_ss = ss.transform(X_test_ano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ここから学習していく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル作成\n",
    "clf = OneClassSVM(nu=0.1, kernel=\"rbf\")\n",
    "# 学習\n",
    "clf.fit(x_train_ss)\n",
    "# 予測\n",
    "pred_train = clf.predict(x_train_ss)\n",
    "pred_test_no = clf.predict(x_test_no_ss)\n",
    "pred_test_ano = clf.predict(x_test_ano_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正常データは１， 異常データは-１として返される"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1, -1,  1, -1,  1,  1, -1,  1,  1,  1,  1,  1,  1, -1,  1, -1,\n",
       "        1,  1,  1,  1, -1, -1,  1, -1,  1, -1,  1, -1,  1, -1, -1,  1,  1,\n",
       "       -1, -1,  1, -1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 細かい数値がほしいならこちら： 上記の結果と比較するとわかるが0より大きい場合は正常，小さい場合は異常と判断される\n",
    "clf.decision_function(x_train_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, -1,  1, -1, -1,  1, -1,  1,  1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.decision_function(x_test_no_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.decision_function(x_test_ano_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル作成\n",
    "clf2 = OneClassSVM(nu=0.1, kernel=\"rbf\")\n",
    "# 学習\n",
    "clf2.fit(x_train_ss)\n",
    "# 予測\n",
    "pred_train2 = clf.predict(X_train_no)\n",
    "pred_test_no2 = clf.predict(X_test_no)\n",
    "pred_test_no2  = clf.predict(X_test_ano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_no2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_no2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 評価について"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[混同行列(Confusion Matrix) とは 〜 2 値分類の機械学習のクラス分類について](https://qiita.com/TsutomuNakamura/items/a1a6a02cb9bb0dcbb37f)<br>\n",
    "\n",
    "|  | 予測(Positive) | 予測（Negative） |\n",
    "| :--- | :---: | :---: |\n",
    "| 実際(Positive) | TP(True Positive) | FN(False Negative) |\n",
    "| 実際(Negative) | FP(False Positive) | TN(True Negative) |<br>\n",
    "<br>\n",
    "\n",
    "・真陽性（TP: True Positive）: 実際のクラスがPositiveで予測もPositive（正解）<br>\n",
    "・真陰性（TN: True Negative）: 実際のクラスがNegativeで予測もNegative（正解）<br>\n",
    "・偽陽性（FP: False Positive）: 実際のクラスはNegativeで予測がPositive（不正解）<br>\n",
    "・偽陰性（FN: False Negative）: 実際のクラスはPositiveで予測がNegative（不正解）<br>\n",
    "\n",
    "他人受入率;誤受理率（False Acceptance Rate; FAR） ＝ FP / (TN + FP) =  FPR<br>\n",
    "他人と判断すべきなのに本人と判断した<br>\n",
    "\n",
    "本人拒否率;誤棄却率（False Rejection Rate; FRR） ＝ FN / (FN + TP) = FNR<br>\n",
    "本人と判断すべきなのに他人と判断した<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価用関数\n",
    "def far_frr(normal_result, anomaly_result):\n",
    "    tp = np.count_nonzero(normal_result == 1)\n",
    "    fn = np.count_nonzero(normal_result == -1)\n",
    "    fp = np.count_nonzero(anomaly_result == 1)\n",
    "    tn = np.count_nonzero(anomaly_result == -1)\n",
    "    re_accuracy = (tp + tn) / (tp + fn + fp + tn)\n",
    "    re_far = fp / (tn + fp)\n",
    "    re_frr = fn / (fn + tp)\n",
    "\n",
    "    # accuracy = ((TP+TN)/(TP+FN+FP+TN))\n",
    "    # print(accuracy)\n",
    "    return re_far, re_frr, re_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "far, frr, accuracy= far_frr(pred_test_no, pred_test_ano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 異常データはきちんと弾いたが一部正常データも弾いた"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ハイパーパラメータいじるならこんな感じ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def test(nu, gamma):\n",
    "    # モデル作成\n",
    "    clf = OneClassSVM(nu=nu, kernel=\"rbf\", gamma=gamma)\n",
    "    # 学習\n",
    "    clf.fit(x_train_ss)\n",
    "    # 予測\n",
    "    pred_train = clf.predict(x_train_ss)\n",
    "    pred_test_no = clf.predict(x_test_no_ss)\n",
    "    pred_test_ano = clf.predict(x_test_ano_ss)\n",
    "\n",
    "    far, frr, accuracy = far_frr(pred_test_no, pred_test_ano)\n",
    "#     print(f'contamination={nu} and gamma={gamma}')\n",
    "#     print(f'FAR:{far}\\nFRR{frr}\\nAccuracy{accuracy}\\n')\n",
    "    return far, frr, accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 33.08it/s]\n"
     ]
    }
   ],
   "source": [
    "contamination=0.1\n",
    "lst=[]\n",
    "for nu in tqdm(np.linspace(0.01, 1, 100)):\n",
    "    for gamma in np.linspace(0.01, 1, 50):\n",
    "        far, frr, accuracy = test(nu, gamma)\n",
    "        lst.append([nu, gamma, far, frr, accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.columns = ['nu', 'gamma', 'far', 'frr', 'accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
